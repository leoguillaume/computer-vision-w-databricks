{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a été extrait de databricks. Il regroupe le code permettant le traitement distribué des données : de l'import des images depuis Google Cloud Storage jusqu'à l'enregistrement des features et prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c8cdcac6-c693-4b0e-9b5f-6a821bc4948b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bases\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Pyspark SQL\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Pyspark ML\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "from pyspark.ml.feature import StandardScaler, PCA, StringIndexer\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a31127ce-e350-4e7b-9561-069456a80ab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "\n",
    "INPUT_FILE_PATH = \"/FileStore/tables/fruits-360-original-size/\"\n",
    "N_COMPONENTS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "203529e6-90a9-4e59-911f-51cb12003a5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Number of images: 6676\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Number of images: 6676\n</div>",
       "datasetInfos": [
        {
         "name": "images",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "modificationTime",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "length",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "content",
            "nullable": true,
            "type": "binary"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read images data with a binary format (images are binary)\n",
    "images = spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.jpg\").option(\"recursiveFileLookup\", \"true\").load(INPUT_FILE_PATH)\n",
    "print(f\"Number of images: {images.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pretrain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG-16 est un réseau de neurone de convolution à 16 couches. Il a été pré-entrainé sur plus d'un million d'images du dataset ImageNet. Le modèle pré-entrainé classifie 1000 catégories d'image (objets et animaux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = VGG16(input_tensor=Input(shape=(224, 224, 3)))\n",
    "model = Model(inputs=pretrain_model.inputs, outputs=pretrain_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3ddd6afe-e37f-46d5-a383-37e51e3d8dbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/functions.py:386: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
       "  &#34;in the future releases. See SPARK-28264 for more details.&#34;, UserWarning)\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/functions.py:386: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n  &#34;in the future releases. See SPARK-28264 for more details.&#34;, UserWarning)\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@udf(StringType())\n",
    "def get_label(x):\n",
    "    return x.split('/')[-2].split('_')[0]\n",
    "\n",
    "def model_fn():\n",
    "  \"\"\"\n",
    "  Returns a VGG16 model with top layer removed and broadcasted pretrained weights.\n",
    "  \"\"\"\n",
    "  pretrain_model = VGG16(input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "  # remove two lasts layers to return 4096 features instead of classification predictions\n",
    "  model = Model(inputs=pretrain_model.inputs, outputs=pretrain_model.layers[-2].output)\n",
    "  return model\n",
    "\n",
    "def preprocess(content):\n",
    "  \"\"\"\n",
    "  Preprocesses raw image bytes for prediction.\n",
    "  \"\"\"\n",
    "  # open image (binary format) and resize it (224 on 224 pixels) \n",
    "  img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "  # convert image to an numpy array\n",
    "  arr = img_to_array(img)\n",
    "  return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "  \"\"\"\n",
    "  Featurize a pd.Series of raw images using the input model.\n",
    "  :return: a pd.Series of image features\n",
    "  \"\"\"\n",
    "  input = np.stack(content_series.map(preprocess))\n",
    "  preds = model.predict(input)\n",
    "  output = [p.flatten() for p in preds]\n",
    "  return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "  '''\n",
    "  This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "  The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "  \n",
    "  Parameters\n",
    "  ----------\n",
    "      content_series_iter: \n",
    "        This argument is an iterator over batches of data, where each batch is a pandas Series of image data.\n",
    "  '''\n",
    "  model = model_fn()\n",
    "  for content_series in content_series_iter:\n",
    "    yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "553b1169-cb17-4597-8944-1249610d3ca7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Number of extract features per image: 4096\n",
       "+--------------------+--------------------+\n",
       "                path|            features|\n",
       "+--------------------+--------------------+\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 1...|\n",
       "+--------------------+--------------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Number of extract features per image: 4096\n+--------------------+--------------------+\n|                path|            features|\n+--------------------+--------------------+\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 1...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [
        {
         "name": "features_df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "features",
            "nullable": true,
            "type": {
             "containsNull": true,
             "elementType": "float",
             "type": "array"
            }
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# partition dataset in 16 parts\n",
    "features_df = images.repartition(16).select(col(\"path\"), featurize_udf(\"content\").alias(\"features\"))\n",
    "\n",
    "features = np.array(features_df.select('features').limit(1).collect()[0])\n",
    "print(f\"Number of extract features per image: {features.shape[1]}\")\n",
    "\n",
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve labels and encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "933d9c40-18fa-4a1b-94a5-67cb09cc8a96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+--------------------+-------+----------+\n",
       "                path|            features|  label|labelIndex|\n",
       "+--------------------+--------------------+-------+----------+\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|  apple|       0.0|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|  apple|       0.0|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|  apple|       0.0|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|cabbage|       6.0|\n",
       "dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 1...|cabbage|       6.0|\n",
       "+--------------------+--------------------+-------+----------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------------+--------------------+-------+----------+\n|                path|            features|  label|labelIndex|\n+--------------------+--------------------+-------+----------+\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|  apple|       0.0|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|  apple|       0.0|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|  apple|       0.0|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 0...|cabbage|       6.0|\n|dbfs:/FileStore/t...|[0.0, 0.0, 0.0, 1...|cabbage|       6.0|\n+--------------------+--------------------+-------+----------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [
        {
         "name": "features_df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "features",
            "nullable": true,
            "type": {
             "containsNull": true,
             "elementType": "float",
             "type": "array"
            }
           },
           {
            "metadata": {},
            "name": "label",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {
             "ml_attr": {
              "name": "labelIndex",
              "type": "nominal",
              "vals": [
               "apple",
               "pear",
               "zucchini",
               "cucumber",
               "eggplant",
               "carrot",
               "cabbage"
              ]
             }
            },
            "name": "labelIndex",
            "nullable": false,
            "type": "double"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_label = udf(lambda x: x.split('/')[-2].split('_')[0], StringType())\n",
    "features_df = features_df.withColumn('label', extract_label(features_df['path']))\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\") \n",
    "features_df = indexer.fit(features_df).transform(features_df) \n",
    "\n",
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ccc805cb-af99-445b-9f90-417257e38170",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [
        {
         "name": "features_df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "features",
            "nullable": true,
            "type": {
             "containsNull": true,
             "elementType": "float",
             "type": "array"
            }
           },
           {
            "metadata": {},
            "name": "label",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {
             "ml_attr": {
              "name": "labelIndex",
              "type": "nominal",
              "vals": [
               "apple",
               "pear",
               "zucchini",
               "cucumber",
               "eggplant",
               "carrot",
               "cabbage"
              ]
             }
            },
            "name": "labelIndex",
            "nullable": false,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "vectors",
            "nullable": true,
            "type": {
             "class": "org.apache.spark.ml.linalg.VectorUDT",
             "pyClass": "pyspark.ml.linalg.VectorUDT",
             "sqlType": {
              "fields": [
               {
                "metadata": {},
                "name": "type",
                "nullable": false,
                "type": "byte"
               },
               {
                "metadata": {},
                "name": "size",
                "nullable": true,
                "type": "integer"
               },
               {
                "metadata": {},
                "name": "indices",
                "nullable": true,
                "type": {
                 "containsNull": false,
                 "elementType": "integer",
                 "type": "array"
                }
               },
               {
                "metadata": {},
                "name": "values",
                "nullable": true,
                "type": {
                 "containsNull": false,
                 "elementType": "double",
                 "type": "array"
                }
               }
              ],
              "type": "struct"
             },
             "type": "udt"
            }
           },
           {
            "metadata": {
             "ml_attr": {
              "num_attrs": 4096
             }
            },
            "name": "scaled_vectors",
            "nullable": true,
            "type": {
             "class": "org.apache.spark.ml.linalg.VectorUDT",
             "pyClass": "pyspark.ml.linalg.VectorUDT",
             "sqlType": {
              "fields": [
               {
                "metadata": {},
                "name": "type",
                "nullable": false,
                "type": "byte"
               },
               {
                "metadata": {},
                "name": "size",
                "nullable": true,
                "type": "integer"
               },
               {
                "metadata": {},
                "name": "indices",
                "nullable": true,
                "type": {
                 "containsNull": false,
                 "elementType": "integer",
                 "type": "array"
                }
               },
               {
                "metadata": {},
                "name": "values",
                "nullable": true,
                "type": {
                 "containsNull": false,
                 "elementType": "double",
                 "type": "array"
                }
               }
              ],
              "type": "struct"
             },
             "type": "udt"
            }
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format features to Spark vector format\n",
    "array_to_vector = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "features_df = features_df.withColumn('vectors', array_to_vector('features'))\n",
    "\n",
    "# Scaling\n",
    "standardizer = StandardScaler(inputCol=\"vectors\", outputCol=\"scaled_vectors\", withStd=True, withMean=True)\n",
    "features_df = standardizer.fit(features_df).transform(features_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(k=N_COMPONENTS, inputCol='scaled_vectors', outputCol='pca_vectors')\n",
    "features_df = pca.fit(features_df).transform(features_df)\n",
    "\n",
    "# Save features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a1999121-258c-4926-b751-8136d18fd29b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'pca_vectors', labelCol = 'labelIndex')\n",
    "model = rf.fit(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3ef5eab8-b244-4c18-ac5c-e75977290a06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_df = model.transform(features_df)\n",
    "predictions_df = predictions_df.select(col('path'), col('probability'), col('prediction'))\n",
    "\n",
    "predictions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.withColumn('pca_features', vector_to_array('pca_vectors'))\n",
    "features_df = features_df.select(col('path'), col('label'), col('features'), col('pca_features'))\n",
    "\n",
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ce6bdf0d-7cfb-4818-8918-798c4adb5a6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_df.write.mode(\"overwrite\").parquet(\"dbfs:/ml/tmp/fruits-360-original-size-features/features\")\n",
    "features_df.write.mode(\"overwrite\").parquet(\"dbfs:/ml/tmp/fruits-360-original-size-features/predictions\")\n",
    "model.save(\"dbfs:/ml/tmp/fruits-360-original-size-features/model\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "p8",
   "notebookOrigID": 3452871867031529,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
